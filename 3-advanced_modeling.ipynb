{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4a299f-d08d-4cb5-836c-edddd00e2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9371a590-a259-434d-be82-345ac766f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from utils.misc import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2010fd2d-c73e-46c8-8d30-aab055ab0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37304afd-9a42-420e-97d0-67a7e454caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/mimii-anomaly-detection'\n",
    "MERGE_MACHINE_ID = True\n",
    "\n",
    "file_paths = sorted(glob.glob(DATA_PATH + '/*/*' if MERGE_MACHINE_ID else DATA_PATH + '/*/*/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8763023-cb97-4bb9-a866-b534b1567ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db: 6dB, machine type: fan\n"
     ]
    }
   ],
   "source": [
    "file_path = file_paths[0]\n",
    "file_path_split = file_path.split('/')\n",
    "suffix = '_'.join(['', file_path_split[-1], file_path_split[-2]])\n",
    "\n",
    "if MERGE_MACHINE_ID:\n",
    "    print('db: {}, machine type: {}'.format(file_path_split[-2], file_path_split[-1]))\n",
    "\n",
    "else:\n",
    "    print('db: {}, machine type: {}, machine id: {}'.format(file_path_split[-3], file_path_split[-2], file_path_split[-1]))\n",
    "    suffix = '_'.join([suffix, file_path_split[-3]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c40a2a8-124a-4ff1-a225-86403ea76c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = defaultdict(list)\n",
    "\n",
    "for key in ['train_files', 'test_files', 'train_labels', 'test_labels']:\n",
    "    file_name = os.path.join(DATA_PATH, 'dataset', key + suffix + '.txt')\n",
    "    with open(file_name, 'r') as f:\n",
    "        for item in f:\n",
    "            dataset[key].append(item[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae6caa0e-a16f-48bb-9493-13eeb842099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(DATA_PATH, 'dataset', 'train_data' + suffix + '.pkl')\n",
    "\n",
    "if os.path.exists(train_data_path):\n",
    "    train_data = load_pickle(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b1fd760-2141-49a4-95e7-adf2f63607f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 64\n",
    "frames = 5\n",
    "latent_dim = 2\n",
    "\n",
    "input_dims = n_mels * frames\n",
    "input_layer = Input(shape=(input_dims, 1))\n",
    "h = Conv1D(filters=32, kernel_size=3, strides=2, activation='relu')(input_layer)\n",
    "h = Conv1D(filters=64, kernel_size=3, strides=2, activation='relu')(h)\n",
    "h = Flatten()(h)\n",
    "h = Dense(latent_dim + latent_dim)(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3d03c0-1918-46d3-a27c-6dd456901760",
   "metadata": {},
   "source": [
    "* https://www.tensorflow.org/tutorials/generative/cvae?hl=ko\n",
    "* https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "112f2574-ce85-4e2a-8b59-202c20152d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "  \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dim):\n",
    "    super(CVAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            # No activation\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "  def encode(self, x):\n",
    "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "  def reparameterize(self, mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "  def decode(self, z, apply_sigmoid=False):\n",
    "    logits = self.decoder(z)\n",
    "    if apply_sigmoid:\n",
    "      probs = tf.sigmoid(logits)\n",
    "      return probs\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd309fc0-8f04-4a93-ba88-4bf5b4161acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "  mean, logvar = model.encode(x)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  x_logit = model.decode(z)\n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "  \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = compute_loss(model, x)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad2fd44-81b9-4ce1-aae4-0731d30556c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
